{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "220614_복습.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "kQO5mPYY8yO_",
        "iwewdVJe_VVq",
        "5Hsw4d_GDwJ-"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 02. 텍스트 전처리"
      ],
      "metadata": {
        "id": "kQO5mPYY8yO_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "한국어에서 영어에서의 단어 토큰화와 유사한 형태를 얻으려면 어절 토큰화가 아니라 형태소 토큰화(morpheme tokenization)를 수행해야 한다.\n",
        "\n",
        "한국어 자연어 처리를 위해서는 KoNLPy(코엔엘파이)라는 파이썬 패키지를 사용할 수 있다. KoNLPy를 통해서 사용할 수 있는 형태소 분석기로 Okt(Open Korea Text), 메캅(Mecab), 코모란(Komoran), 한나눔(Hannanum), 꼬꼬마(Kkma)가 있다."
      ],
      "metadata": {
        "id": "S1D9ooNE9XE2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
        "\n",
        "print('단어 토큰화1 :',word_tokenize(\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"))\n",
        "print('단어 토큰화2 :',WordPunctTokenizer().tokenize(\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"))\n",
        "print('단어 토큰화3 :',text_to_word_sequence(\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2nwiqcF83OZ",
        "outputId": "4805dcee-6a69-4b44-81e5-d912521f2fff"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 토큰화1 : ['Do', \"n't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', ',', 'Mr.', 'Jone', \"'s\", 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop', '.']\n",
            "단어 토큰화2 : ['Don', \"'\", 't', 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', ',', 'Mr', '.', 'Jone', \"'\", 's', 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop', '.']\n",
            "단어 토큰화3 : [\"don't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', 'mr', \"jone's\", 'orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Okt\n",
        "from konlpy.tag import Kkma\n",
        "\n",
        "okt = Okt()\n",
        "kkma = Kkma()\n",
        "\n",
        "print('OKT 형태소 분석 :',okt.morphs(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))\n",
        "print('OKT 품사 태깅 :',okt.pos(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))\n",
        "print('OKT 명사 추출 :',okt.nouns(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\")) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnLMUbyb9-A9",
        "outputId": "f98de979-108d-496b-f0b8-97662bd86225"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OKT 형태소 분석 : ['열심히', '코딩', '한', '당신', ',', '연휴', '에는', '여행', '을', '가봐요']\n",
            "OKT 품사 태깅 : [('열심히', 'Adverb'), ('코딩', 'Noun'), ('한', 'Josa'), ('당신', 'Noun'), (',', 'Punctuation'), ('연휴', 'Noun'), ('에는', 'Josa'), ('여행', 'Noun'), ('을', 'Josa'), ('가봐요', 'Verb')]\n",
            "OKT 명사 추출 : ['코딩', '당신', '연휴', '여행']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "text = \"나랑 점심 먹으러 갈래 점심 메뉴는 햄버거 갈래 갈래 햄버거 최고야\"\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n",
        "print('단어 집합 :',tokenizer.word_index)\n",
        "\n",
        "sub_text = \"점심 먹으러 갈래 메뉴는 햄버거 최고야\"\n",
        "encoded = tokenizer.texts_to_sequences([sub_text])[0]\n",
        "print(encoded)\n",
        "\n",
        "one_hot = to_categorical(encoded)\n",
        "print(one_hot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhdqumnB-773",
        "outputId": "a4c73575-0261-4a61-a55a-a34306ff7ef9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합 : {'갈래': 1, '점심': 2, '햄버거': 3, '나랑': 4, '먹으러': 5, '메뉴는': 6, '최고야': 7}\n",
            "[2, 5, 1, 6, 3, 7]\n",
            "[[0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 03. 언어모델"
      ],
      "metadata": {
        "id": "iwewdVJe_VVq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 언어 모델\n",
        "  - 단어 시퀀스에 확률을 할당(assign) 하는 일을 하는 모델\n",
        "  - 가장 자연스러운 단어 시퀀스를 찾아내는 모델\n",
        "단어 시퀀스에 확률을 할당하게 하기 위해서 가장 보편적으로 사용되는 방법은 언어 모델이 이전 단어들이 주어졌을 때 다음 단어를 예측하도록 하는 것\n",
        "  - SLM : 통계에 기반한 전통적인 언어 모델\n",
        "\n",
        "* 언어 모델링(Language Modeling)\n",
        "  - 주어진 단어들로부터 아직 모르는 단어를 예측하는 작업\n",
        "\n",
        "* N-gram\n",
        "  - n개의 연속적인 단어 나열\n",
        "  - 갖고 있는 n개의 단어 뭉치 단위로 끈헝서 이를 하나의 토큰으로 간주\n",
        "  - 최대 5를 넘게 잡아서는 안 된다고 권장됨"
      ],
      "metadata": {
        "id": "RRTN1DFz_X3P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 04. 카운트 기반의 단어 표현"
      ],
      "metadata": {
        "id": "5Hsw4d_GDwJ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![wordrepresentation.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAf8AAAERCAYAAAB1v65MAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAC7xSURBVHhe7Z09iFXbHfYvJCQ3YGAKCwPCO6CFhYUQC4tbWAhaTGFhMYRbCDGgRIIQyWshmfBKEJFgYWEhYQqL4WIhwWICBgwR7gSGMIWFBBEDU0xhYWCKW1js9z47+/H+XXefM/uc2Wef/fH7weKs76+91nrW/jyfZQAwN168eJF99tln+S98x9mzZ3MDALMB8QcoQcJz5MiRwvU/JNLR782bN7nf2tpa4TM548TfYdHsp6x5UFXE79y5k7fPIP4AswXxByjBYiSBFxJiiVH0kxBH9zRUEX8L/pUrV3J3l9BmqYqId7FtAF2G2QZQQiq82gzISMiin68EeCNgYzG3f9w4xLgWvSri73TebDitjAU2LU9G9RTe0DhMxLrYT8S8ZRcqN8Z1nWWP5bku0U9mlJ/rZaN8Fc/5CPWzw6O/3WVhADAaxB9gBBIcC59ERaIkd/STPRVpi1kUeguwBdRupZfbQhpJ81V53mwove3C8dLyYl1sd37O35uJtD1pnWLaWL78bXf5Tiv/UYKsMNfT/WCUxuliu4Xi+RiMKxsARoP4A4xAAiPhsWALCYzFxkJjUTWOr7ipINltwZV/DI84zCYKoOoVw2RU31H5yz9uBITd0agM11/G9UrrYuO4FuNYnlB+FnGR1tvp9Cu3UTynk783CUJx4zEYVTYAjAbxBxiBhVS/FiKLXRT8WYu/0sRyRRTHyKj85e96Oiytd4ryV7h+x9VT/lXEP81DYYg/wHxA/AFGYMGV0ETxkXucqEVRtRg7LBUoi57DI2lc5yt/26OQy+7yXN8oqmmaNH+5bTejhFbYHv3TPKOIu26K43hO57qZmC7aheK5fTGPtGwAGA3iDzAGCZ8ERcJiJDZRgISFzcYCGwXPWOhknFcMN2ViJhF0fNtlXBeX53o7rnC5rpuIdbHAulwbp0/9jeyjBDj2i3C9VJbsTqc6OZ7yULjrI2J7nEZEd1o2AIwG8QfoERZbCzYAQBmIP0CPQPwBoAqIP0CPQPwBoAqIPwAAwMBA/AEAAAYG4g8AADAwEH+AHvPNN99kW1tb+bMAv/vd77If/ehH2Y9//OPsxIkT2d27d7OnT59mb9++LWIDwFBA/AF6QBT5GzduZOfPn8+OHTuWLSwsZKdOncouX76c3bt3L/vLX/6S/e1vf/tevAMHDmQnT57MLl68yKYAYAAg/gAdoqrIr6+vZzs7O0WqvRmVb9mmYHt7u0gFAF0F8QdoIbMS+UlpSz0AoF4Qf4A5MskZd5suw+/u7mabm5vZ6upqdv369WxpaSlbXFxkUwDQERB/gAboqshPCpsCgG6A+APUyFBEflLYFAC0C8QfYApGifznn3+ev0a3vLyc3b59O3vy5En2+vXrIhWkaFOwsbGRPXjwILt27Vp27ty57NChQ2wKAGYM4g8whg8fPmQvX77MHj9+nK2srIwV+VevXhWpYL+8f/9+7Kbg6tWr2f3797Pnz59n7969K1IBQFUQf4BvSUX+woUL2fHjx/PL9Yh8exi1KTh48GB2+vRpNgUAFUH8YVCMEnmdyetXbvkrXPGgG2hTIMGX8GsDoI2ANgRsCgDKQfyhl0wq8ooP/UNCz6YA4Psg/tBpEHmYBjYFMHQQf+gEo0T+hz/8Yf4Anh7E01P3evpeT+Ej8jANEnq9WaA3DPSmgR4u1EOGZZsC3WoA6CqIP7SKSUVer9wBzBq9Zli2KdDDhnroUA8f6iFEPYzIpgC6AOIPcwGRhz7ApgC6CuIPM0dCXyby+sKbvvSmL77py2/6AhwiD31A/3yorzjqa476qqO+7qjXRtNNAX+bDPMC8YdGkOhHkdeX3QCGhsQ+bgpkB5gHiD8AAMDAQPwBAAAGBuIPAAAwMBB/ABg0n332WXbnzp3CBfOC49AsiH/DXLlyJTty5EjhAvHixYt84usXoAyPEZv9jJV0DrZRdNL2yui11y6gvlR99yKNJzvi3xyIf4In3awm2jjxV5jKjqZLuO+qLMyK54k+SToYHhaJOD7Onj1b2CZHadu+Afec8DrktaELVK1rl9rUR+j5hHTS1U0V8Teyy68rqM9U571E/M2bN3k8dvlQhXFjxWPOxmPPc0lC7zCNO/tHP/0qf9tjGs+/dMMQw7xm2IwSbKX3psUbGhn7RdJ1yO1UHUVZHZ2//WVE2i7lZT8b91tM7z5P+1i4/jG+8ojtsl9Zn5fF06/LTOtn/1HlwuQg/gkehJ50EU0uDzgNvoj9nTadMM5PE6Gq+KuMWE5ZfqMmvIhhXiBiXPsJ+8l4MsVJ63q4XTEf+bnfbDRJy/xE9FM+judy075L/dOyob+kYyPiMI8BC4OEw2PX6WSPcyDOQYUpbRRJEfMrS6P8nMZj22NU5boOxvPRacaN3bRtsXzl6zo6L8VXeCxP9lhHpxExb9VdaV13xTeuh/2Uh/J03zgPt02k7Y44vUjjye5+lN3xYl+MKxcmo/wIDZh00hkNME8+EQen/GNYiieXUJpRceNk8IT1ZFAa2z1JhfxtF2m9Ypj8PVHiolFWp1hnobgq12W7LrFfHKY8U2Kd07a5z/Wb9r/iyK0048qGfhLHRorHhvG40jiJc0lonHjsl81l5ZWOyziey9KoDMdRWuM8xtVB/jIe5ylut00sW/YYJqPy5K8yjes8ar6l5quvvvpod3uUJsaRUZ72d7zYP2m77bZxH6TxZFe+ZcfcbRtXLkzGdz0POR546aT0wDQaiHFipfG9KEQjnK6MdJK4PJeRGtXVk8LEyaBfTzQhd5qHyvCEivVSujSuynG7PDFdZ5GGuS+jUVvcHrfP8fTrupjYv+PKhn6SjpXIuLGSjo04F1LBcP5pWXG8laWJ80FpjfMYVwfh8Jiv8ZxQ/mm9FF9pU1J/1zlNH+dbGUqjcOWlNLKn2N/tjv0T2+2y1Q6heO6DGE/IrnzL6ue2jSsXJuP7R3XgxEkX8cA0GohxYqXxPVhFnEBOV0acDHGQjypDxHJEnAz69UQTadyIy3A5cZJGFKY4npixzmlYzMNhsT3uzzjZY1+J2PZxZUN/8XH2cRcaV3HciHSexbER54LCPEeE4iltOi7jeIv5uVz5xfEp4jh3fWR3vHROpePduAzn63hpXYTcQm2yf2xLtBu5nU5Eu/DcTesht+yxbUJx3aexTTF92gcxnpDddYx256HfceXCZHx/1A2cdLAbTwYTB2dcWIzCyyal/EYNVoU5nlA8x03LKMs7neRlaWL+ziPi9Okkk1t29Yv81U8i5hknqYjl6zfmJ7vrGdOlebgeYlzZ0G88Dmw8jjwmUv90bMSx6DHm+Pr1+LZdxPHmMBmPZc+fmJ+Mx6ewn8p3HWJeMulaI5xnDHO5ClNeaXqXYX+3N22XSOssRvVl7HvnaT/Hkb/KFrF9Ksf1dvvTejmefl3HGCbjNo4rFyaDlTMhnRRx4MWJlQpnGj9OmLgQyT5qsKYLlieA4qeTwYNfYbFenlhC/tEtYly3y+XKKNworf09Kb1AqJ9EWmfnr/iOK+N4rrfdKsN97jxjuphmr7IBhkzZfAcYBStnx2HCA4BgLYBJQPw7DhMeAARrAUwC4t9xmPAAADApiD8AAMDAQPwBAAAGBuI/EHZ3dwsbAPQB5jTsB8S/5+zs7GS/+c1vsh/84AfZr3/96+z169dFCAB0EeY01AHi31O0IFy8eDFbWFjIrl69mv3yl7/Mrl27lh04cCD339raKmICQBdI5/TXX3/NnIapQfx7hhaA8+fPZwcPHsxu3LiRnyUIfwzn/fv32crKSr6AKN7GxkbuDwDtZNScNsxpmAbEvyc8f/48O3fuXHbo0KHs9u3b+YIQSb+Ep/uF9+7dy+OfPn06W19fL0IAoA3sNadTmNMwCYh/x3ny5El26tSp7OjRo/nE/+abb4qQTxn1GVzFX11dzdOfOHEiz+/Dhw9FKAA0TdU5PQrmNFQB8e8gmsia3MePH88nt+x7Te69voGv9FoklJ8WDeU56aIDANMxzZzeC+Y0jAPx7xCauDoT0ET+4osv8oldlUn+AOfZs2f5ZUNdPpzmzAMAqrGfOT0JzGlIQfw7gO713bp1K5+4S0tL+b3ASZlE/I0eHNIDRHqQSA8U7XXPEQCqUcecngbmNBjEv8XoqV493aunfJeXl/f1Ks804m9evnyZv0qkV4r0alH6tDEAVKPOOb0fmNOA+LcQvc+r93i1O798+XItH/HYj/ibt2/f5guF6qWFg4+LAFRjFnO6DpjTwwXxbxE6C/jyyy/zs4Lr16/XuhuvQ/yN6qVLhqqnLiHO6+wFoO3Mck7XCXN6eCD+LeDFixf5hNP9v1ndh6tT/I3qeffu3bzeeh+5qfuWAG2niTk9C5jTwwHxnyNPnz7Nn8BdXFyc+RO4sxB/o3o/ePAgf2JZ7yfP6ollgLbT5JyeJczp/oP4N4zevX38+HH+7q3e6a3jfd4qzFL8jdqxtraWt62ud5UB2s685nQTMKf7C+LfENpJP3z4cG476SbEP+IzILWX94qhj8x7TjcNc7pfIP4zRvfQNFHmfQ+tafE3aq/vfVb5PjlA22nLnJ4XzOl+gPjPiHfv3n18evbChQtzf3p2XuJv4lPPZf9MBtB22jan5w1zutsg/jWzvb398b3ZS5cutea92XmLv4nvO6ufeK8Y2k5b53RbYE53E8S/Jl69epV/JMMToG274LaIv1H/+Etn6jfeK4a20fY53TaY090C8d8nGuC6/6UB3+b3edsm/kb95W+cqx/17XGAedKVOd1WmNPdAPGfEj30oidfDx8+3IknX9sq/kb9p37Uk8Tq1/X19SIEoBm6NqfbDnO63SD+E6LXefS+67Fjxzr1zmvbxd+oP9Wvfq9Y/c17xTBLujqnuwJzup0g/hXw4NXicPLkyU6+z9sV8Y+on/Uf5zpzUP9zJgZ10Yc53UWY0+0B8R+DL1vpMuCZM2c6/T5vF8XfqN/1PrXuIXI5FvZDn+Z0l2FOzx/EvwQ9sKIHffzASh+eWu2y+BsdB71fzYNYMCl9nNN9gDk9PxD/gF5V0Ss9flWlT++r9kH8jY6L3rfmFSzYiz7P6T7BnG4exP9bhjDw+iT+hoUdRoGYdBPmdHMMWvx1yWl5eXkQl5z6KP6GS7pghjSn+wxzevYMUvz1sMnS0tKgHjbps/ib+DDXEP9wZcgMcU4PAeb07BiU+KevmQzpXdMhiL+Jr3EN4a9Wh8yQ5/SQYE7XT+8VQYPm0aNHn3xgYogMSfwjOt4+9ohDP2BODxvmdD30VhF0uej+/fsfPy059MtFQxV/o+OvcaDxwGXhbsKchghzen/0ThH0oMjdu3c/PiiyublZhAyboYu/0YNDGhcaH7dv3+aBsA7AnIZxMKenozeKoFdEbt68+fEVEf0dJ3wH4v8peoVI40TjRX9Dyqtg7YM5DZPAnJ6MziuCDrjeC/X7vNvb20UIRBD/cvxesccP7xXPH+Y07AfmdDU6qwgvX778uMvT+6Dv3r0rQqAMxH88Gj8aRz7L5L3i5mFOQ50wp8fTOUXY2Nj4eH9HD3ns7u4WITCOxcXFwgbj0HjSuPL9ZY03mC3MaZglzOlyOiP+6+vrH5/s1OsdPNkJs0TjS+PMT5Y/e/asCIG6YE5DkzCnP6UT4q/3OLVj0/udvNMJTaLxpnGn8cfYqw/mNMwL5vT/4EYwAADAwED8AQAABgbiDwAAMDAQfwCoxJ07dz6+MhrtVTly5Eh25cqVwtU9pmkzQFtpdCT/481/s8+u/T371Vf/LnygDPWP+mnp4cvC53+U+UH/ePPmTS4ya2trhc/kKK3yiObFixdF6HRMKv4Segm+qVv8Z9HGcSD+MC3pXGgD3xvJEheJjMzPfv914VsP04q/0/3hr/8pfL5DfmVh9v/zPyf7xOM09asbi39af7mHJv6aNF7YZzl5zp49m5tRuA42szyDrVP8LYZq2377b1Lxq6PMccyijeNA/PePjpX60GZWmzWXMyr/uK7YzJLWi7+F3/z8T/+qdQMwrfhLAJWuTPyF6qi6RuRO/faiLVcmLP46HrH/7TeKdOOmX+GNkPpDv2qnwx1XuP2OJ6M8o1txmkKTJU4YTWQtwLNA5ewl/hb8VHTqZhbiH4XLIhnbHBfD2A/R33aRCmGaPrpl1CaVJ38Tw1N/5eGwWJ9Imfg7H/k5vUwcN9HfadP6m+hvO0yHx0ycN6OO7X7Za46mx9LHd1Yo77iWtYGPrffCHwU2iq4FKQpBPCuNYjJKPEeJi4niJSOcxqZM/Fy3KExyuy0xfWxfWucYT3UUFk4bt9n+bkudohjbo1/3p+xl7Reuj+tXJv6jjovCFCceH+HjoTAxLo+68eSVaJThhcTG8bSYxEkWJ7XFzmkcL/rJlCF/5+O6GeXjtLFsLzAxbSpKrnf0dzqVMy1lwpi212WrL2O9XXaah9spoviXLeoiPRayp8dCqB5Kr3yE7E6X1iHisGjKcDyh8mOdxDTth8lR3/kYp3gM2Die+l5uHQvhsab4tsf5q/hOY1NWpueYkT0tw8bHP83XxPI9vkXqn467efOxBRb6KOjCC74FyUIgcbFI6Nei5HzKxDAVF+cZ7U6nOD4jdZ4uO8X5Oly/zld5WLCiv/K33Tgfx0/LjXV0Xo5bJ2XluC7u57hxUZj83V/CeYiYh4npZRQ/bX+sh1CaUZuPuhk3WdJFOU7kVHDihIyLtyeyJ7zCLEZlKG40TpfiMOfvOgovcLHeLlP+rqcXn1FlVMF9FI1J+yguUjaqi0yM53qldqUv67u0HNmVp/shti/m4fJFepwibmPsT9fJ6aKJgrHf9sNk+Hj4WKW4z0U85tEufAzisXSYjpXHUDo2UjxWbJwuRfEc5vEbieFxfsd6CtnjWGoDH0eyxSUKhLAYpEIQxVn+qZHgWGDtTsXFoiR/xZUxMcx1k98oYnr9SqRcXmqcn+th0vq5zcbhqofrl/ZXHYzq63HiO4n4x74Vsiv+qPY7XlvEPw3zAqFfTcQYJn9PWPmnE1WTVMSwMmI+6YKktHLbKE/nL+MFyAtSamL9hdM6/2kYt/ilfSR3WdvTfvaCltpHpU/LkV15lrUv5qGwUX0dSdtot/KP+UV/EY+NwmLcyLj2w2SkYzxSFuax4jAffx8DHcNoFzqGPl7p2EhR3go3Sucx4HxtnKfC5fbYFAqLcWWUPh1T6VhqAx9bH4XNWCT1O0qQRBSMcaTiEkUoireIYa5HrFtKjO+40Z4i/7TOaf3cZhPzc3lNiL+QW2aU+DqN66NjI7dI6xrzd5j8RrXf9WhS/NOJHUknUlw84gIg5O/JKn9PSAuAyhExrIyYj3DaVFhinkJ5yk+/aVwT6y9cNy940zBu8Uv7KO1ruWVP/ZVGbuGwaE/blR4n2eOxsD1tr+wOc9+U9UXaRqWRWyh/H08fg7R+8lPd0/rLLXvqH9sPk+FjrD5NSce/8PhIj388JunxieN63PgXcawIuZ1W/q5n9BfO1+W6nimqi8efSPNpA5+MZC3sWuxNFPhUCGJYtItRApGKi4VH/s7fxM2A0yn+OBRHaWI+qpfzEa5bWmejtK6fNx2paIqmxd/ljRNft93x9CvK6prGU5np8Unrof4aV37daILFCaOJrEnpCehJHyeW7AoTXjg8ORXHEzJdjNLJmhLziQtSXIBcL+dpXL+0TLllT/2dp/KbFtelbPFTO9OFSH6KH+shon/sW9fROEzG/eh+klEbVab7UDhMJpYpd1lfp7iN0bi9Mcx1Ux1iPWMfTNp+mBz3XxyTHiux333M9ZvODR8Pzx3bHeZjGvMoIz2WSqf0aXmyp3Ml5p3mI7d/o39ZPvPmeyM5CkgUx1QIUvF0GplRgpiKSxR/YSGSSYXZ9RonPk4f47hMG5clVIb9XSfnofKE62jj9LMU/zpQO9I+7CKaMJo4Ml4ohCe+jfHkdXz9ekJ6got0kkexKMNhNs5TRD/9Kk8vEDZehGI5cTEoEyv5AfSJdN5auOO8lYlj3/NBxnNa8Z2X81BYnFNeOzzHIzFPGxPDZHeezs/+JvrHeqfxnU9bKF/poHNoE+INjDc84zZKAAAwXBD/HuGrFgg/AACMA/EHAIDB8c033xS2YYL4AwDAoJDw//SnP83++Mc/Fj7DA/EHAIBB8fr16+wnP/lJ9otf/KLwGR6IPwB0ngcPHgz+Mi5U5+LFi9lvf/vb7MCBA/lGYIgg/gAVWVlZKWxQB3X257lz57Lnz58XLoDRSOwPHjyYvX//Ph+D2ggMEcQfoCJ6Xxfqo87+1CLO5gyqILG/d+9ebtcGQBuBIZ79s5oBVATxr5c6+1Nn/WfOnClcAOW8fPkyO3z48Ce3iLRpXF5eLlzDgdUMoCKIf73U2Z+7u7vZwsJC9uHDh8IH4PucP3/+41m/0dm/xs7W1lbhMwxYzQAqgvjXS939eerUqWxjY6NwAXyKxP3QoUOlD4bq7F8bgyHBagZQEcS/Xuruz+vXr2d3794tXACfUnbWb7Qh0MZgSGf/rGYAFUH866Xu/nzy5Mngzt6gGuPO+o02BkMaP6xmABVB/Oul7v70vVuAFD0M+vDhw8JVjs/+R/0NcN9gNQOoCOJfL7Poz+PHjw/uwS0Yj94EOXr0aKWHQXX2f/r06cLVb1jNACqC+NfLLPrz8uXL+df+AIzEfHV1tXCNR2f/i4uLg/hgFKsZQEUQ/3qZRX8+evRokO9sQzmTnPUbbRSGcPbPagZQEcS/XmbRn2/fvs3v2wKISc76jTYK2jD0/eyf1QygIoh/vcyqP3XZVpsAGDbr6+sTn/UbbRj03Yg+w2oGUBHEv15m1Z+67D/p2R70jxMnTuS3gabBZ/96fbSvsJoBVATxr5dZ9ace+BvqP7XB/5BoS/z3w9ra2r7zaDOsZgAVQfzrZVb9qT9v0VkbDBeJdh1n7XXl00ZYzQAqgvjXyyz7Ux/72dnZKVwwJOo46zd15tU2WM0AKoL418ss+1OfadVlWxgWulevDz3VebYu8e/jWGI1A6gI4l8vs+zP27dvZ1evXi1cMBT0oGfdZ+raSEz71kCbYTUDqAjiXy+z7E/9tW9fL9dCOX5C/+nTp4VPfUzzvYC2w2oGUBHEv15m2Z8Sgs8//zz/sx8YBhLnWX2Zb5ovBbYdVjOAiiD+9TLr/pQQ9PVJbfgUn/XP8qt8fTv7ZzUDqAjiXy+z7s+bN29mN27cKFzQZ/R3vbM66zc++9ef//QBVjOAiiD+9TLr/tTnXfv+iVb47n/4m/gWvzYY+tvfPsBqBlARxL9eZt2fu7u7+X1//UJ/afI/+Le2tvKNRh/O/lnNACqC+NdLE/2pJ/77/u9sQ6bJs36jb0j04eyf1QygIoh/vTTRn9euXctWVlYKF/QNifDS0lLhaoa+nP2zmgFUBPGvlyb6U0/7N3VJGJpFr3FKhCXGTaOzf31IqsuwmgFUBPGvlyb6UwKh+/59eUIbvkNXdCTC80B/HnXw4MFOf0eC1QygIoh/vTTVn9z37x8SXf150zzO+o3+NrrLt5RYzQAqgvjXS1P9yX3//jHPs37z+vXrTp/9s5oBVATxr5em+pP7/v2iDWf9pstn/6xmABVB/Oulqf7kvn+/0Jcbl5eXC9d88dn/u3fvCp/uwGoGUBHEv16a7E/u+/eDnZ2d7MCBA7notoXLly/nt5a6BqsZQEUQ/3ppsj+5798PdBx1qb1NaEOi2xD67RKsZgAVWVxcLGxQB032J/f9u4/+uU+X2Nt01m+0Kenae/+IPwD0Hu7794O2/k9DF8cV4g8Ag0D3/V+8eFG4AIYN4g8Ag6CLl2YBZgXiDwCDQPf9z507V7gAhg3iDwCDQPf99ZqYHhwDGDqIPwAMBt3339jYKFwAwwXxB4DBwH1/gP+B+ANU4A9//U/22bW/Zz/7/deFT/Oo7KWHLwtXP/jVV//O+7UpuO//KW/evMk/trS2tvaJHfaH3ipRX076dsmVK1eyI0eOFK7ZgvhDZ5D4SShsfv6nfxUhs0flSahSvCn48z+/+7qXBDr1U133W98mxV/1j2WpLamf2/6PN/8tfCYnFX/3XSxL7S7bdMlv0j7t+33/O3fu5KITzTiqir/FLJqzZ88Wod1C4iqRnRS1OaZzn0Q/9Z38vvrqq/wX8QeogbjYW4wkQLNG4jaqLIfFjYHrGf3SONOgfJsSf9U/Cq7qnvqpLtE9DVH8dUzdx/H4epMRN1MOj35V6fN9f4u/hLwKk4p/DJO7KaGqE9V7GvHXZie2V32d+u1XvBF/gBIsqsKLv8865S+3jXE8GaXX76gNg0XGRmkt7jYuPxLrpfhyK6/o5/xEzC+KufPXrzcKjid/5ev4sa7yrxuLcuzfsj53ffTr+sgY+7v+0U/G9hT3mY+V4xrVz/m5rjKxL9Ljafp833+U+EfBi0K+H/FP/ey2iXHjFQmJm8uSv1BcuZWH7RJWp7GfTBTHtEzl67xjerddae03qcimfav8XX70U1n216/tsT5ut0jrGesVw+zvehj5O8xtV5mxz5VPCuIPnUELe1zMLZApihfF06JhkbCgRCxsDnNciVAqRCmOKxRH5Tk/+9muukkIhfONdY3iFQXT+bktMd0sKBNfofpEP9ljX4kyoffGx31ht+I574jTOU+5Y9/IrnJj3wr7u7/K+qjP9/3jgi9jUZC9bvEX8lOZTmtRs1grne0xbZX4DlMb5FYa10O/zkN2ofZJ5OxvwXOfyF/I7r6YBOfrdsguVL/oJ3usp+0uU79OW1Y3H7MYT8hfbYp5u07OQ2UrXlrXMhB/6Axa2EcJp/zltokCbKFJBS1iATMx7rh0wuUonurhePJTmOoiU5aP4rtNClM8I3cUL7Xf4bKn4XUTBdZ1dFvcZhHbIBRfYWqv4jqekFv5mrTfhdsW+ykey9jfzj8a1aUsX9Pn+/6pmBj5WXwsHhKGKBLjBCOmichPZcpf9liuw1SuBc24LIULp1c50S4keE4f6+h4qRmXt5DdfTEpqofb682F8pJxHwnb9Wu70gill1v1VB7OR8S+0m+sp9OJWA+nsd1pFDeWm4L4Q2eQKESRkTsKkX7H+Y8T8VQsYtxx6YzD9av4QnW12I3KJwqnwhTfyB3F3e0yrrPMLFBZboPr4TbK7XrHNojYD0ob6ye32mHSfleY06a4/UrjPNL8TJpviu77b25uFq7+EIUlIj+LQhSjKKbRnpIKmIgCJ3/ZY7lyqz4Wp4jLUrhw+piX7GIv8Y9linF5C9ndF5OidKqPftP85baQx76xXfGE4smtek4r/rEeytf18SbAyF9p0v4XiD90Bi3yFhkLqRZ5i41E3oIvUXAc2YUFIYqvSTcKUTzKRDtF9VL9ohBZpJTWYia365PmK7vDRGxvbFckCm3dOG/Vw/3iOstP7ROxr0TcDKi+McxxY384fK+2uD9j2U7j+sktu/tL7jJu3LjRy/v+UVgiWvwtMo4jkYhiGu0pqYA5rsUpTatfueVvu8XXxPQWKcVJ46veFq+y+qo9DpM99U/zS0V1EpyX8nB+Lk9+LlNhLtN2pRXuf6Vzu43zEQqzXcR6x3ooH7nVTzEv4/JSEH/oDBYKGwuMcJhF2CJpcZCxEI0ShBhXxiJkwRuVTljUojhbgFSfiPOXsYiJNL3LlUnbZX+ZmEedxPIj7msLrnDfysT22j+itjhuDI952MQ+j/XxsRExnewmPZ6R9fX17MyZM4WrP0RhiVgsZCwS8rNwpfYUC1g0FjqTxpHbuF4yFrTo5zopjevq9KPEXziuTBrH9Uvzc7mOPwnOWyaivGIZ+rXbdtfZ5Ssv4bQyqeC7X2Rkj8gvbbPjxHrKuOwI4g+DwWIcRQuGif4XfmFhgf/3h8GC+EOviVcHfMYJIE6fPp1fAQAYIog/9Bqf7Zdd+oVhc+vWrfzeP8AQQfwBYJDoK3966h9giCD+ADBI9J6/3vff2eEZEBgeiD8MFj89rqfl4xPoNn4wsCxMRk+T+0nz9In++GT6/336Jv+d1VP5s8TtS2+f2G8S/PS9+qYsP5m0H6ug4+NnO5RHfOJ/L86fP1/6JDRA30H8YbBIMCzIskfhkb+EJL5qZr/0NbOyV98UN/p7MxDTth0LdLTH/piUsv4T8ptEsFPUzxZ/ofzisRjHvXv3sosXLxYuaAMrKyuFrT+0sU2IPwwSi5mFKBV/MWpDkIq/4slEAVM6uaMQyb0fkWua2KZR4q848rcx7isZxfFZv03MR+7YL2lcl618jMv9P//vn5/EFSo7xh3Hq1evssOHDxcuaAN6L71vtLFNiD8MEp+ZG4lFKv4WMDNK/JXOgiWiUOrX4h/jdAG3QbhN0aRn8OoH9ZH8Y1pT1n9Cfukmw3F0XBQW85RbdqNyo9ineezFoUOH8k0AtAPEvxkQfxgkEpAoGPsV/1ScZCz2Fv9JRWmeuD1p3VNBV7/J30btFnbH+FXE33Gi8XFxf8rEPFLxT+u+F7rsf//+/cIF8wbxbwbEHwaJxGYv8ZdfjDNO/IXjW3j6Lv72cxz1g0VcyK5w988k4l+Gy0vz2K/4r66uZktLS4UL5g3i3wyIPwwSiUwUe4lHdFu4osjsJf4W+9RtEbK7K6iuFnsLbxT/2D6HR/EXUcwdf5z4p+XIbbvjxT4X3nQZ55GWMwq96qdX/vjUbztA/JsB8YdB4rNDC4TP2KNJ2Uv8hcIVT0RxFIobRartWGhFKspGbZe/N0+K7761iWlG+bkc4X6WUb7OL+1nGeF+tlvpY9wqnDx5Mnv+/HnhgnmC+DcD4g+DJYpbE0icUvFsM+kGqStI+L0Bq8rNmzf51G9LQPybAfGHQSOhaOJs3GfFXcNn1b560XZ0LKc5nvrbVZ39w/xB/JsB8QeAwcOnftsD4t8MiD8AwLdcuHAhe/ToUeGCeYH4NwPiDwDwLQ8fPsy+/PLLwgXzAvFvBsQfAOBbtre386/9wXxB/JsB8QcAKDh+/Hi2tbVVuGAeIP7NgPgDABRcv349u337duGCeYD4NwPiDwBQ8OzZs+z06dOFC+YB4t8MiD8AQIE+8buwsJDt7u4WPtA0iH8zIP4AAAG98re2tla4oGkQ/2ZA/AEAArzyN18Q/2ZA/AEAAvrK38GDBwsXNA3i3wyIPwBAwqlTp/Lv/UPzIP7NgPgDACSsrKzk//QHzYP4NwPiDwCQsLm5mX/wB5oH8W8GxB8AoITDhw9nb9++LVzQFIh/MyD+AAAlXLp0Kbt//37hgqZA/JsB8QcAKOHp06fZmTNnChc0BeLfDIg/AEAJ+sofX/trHsS/GRB/AIARnDt3Lnvy5EnhgiZA/JsB8QcAGAFf+2sexL8ZEH8AgBG8e/cuv/SvP/yBZkD8mwHxBwAYgx7649J/cyD+zYD4AwCM4cGDB9nFixcLF8waxL8ZEH8AgDFsb2/nf/Tz4cOHwgdmCeLfDIg/AMAefPHFF9mzZ88KF8wSxL8ZEH8AgD24d+9e/sU/mD2IfzMg/gAAe+BL/zB7FhcXC1t/aGObEH8AgAqcOHGC//iH3oD4AwBU4NatW9m1a9cKF0C3QfwBACrw+vXr/G9+eeof+gDiDwBQkVOnTvHUP/QCxB8AoCJ66p8P/kAfQPwBACqys7PDt/6hFyD+AAAToG/9P378uHABdBPEHwBgAlZXV7Pz588XLoDR/PmfO9ln1/6e/7YNxB8AYAJ2d3fzS//6u1+ozs9+/3X28z/9q3B9x9LDl7lAysie4rB/vPlv4dM+/vDX/3ysp4zcAvEHAOgRy8vL2cOHDwsXVKFM/C2aFna5o1D+6qt/5+kUR/Y24s1L3JzIT27EHwCgR+j//fVnP1CdMvGXoKfCGVEaCanSyd42VG/V32f6Kan4p1cI5O84cXPjDYVQ2x2/7MrItCD+AAAToqf99a1/ffMfqlEm/ha+VPyEwySYFk2LaFtwvUZtXtwG/cb2iLjxSTc38le4Nz7CG426+gDxBwCYgsuXL2e3b98uXLAXZeJvFCZhsxiKePZr4avzzLcOUvGP7VBYFH+LvXGbFC/mE+0xP5t0kzQtiD8AwBRsbm728h/oZsU48RcWQ4tbKno2Fto2EMXdRFGvKv5C9vRsX302qw0P4g8AMCUnT57M1tfXCxeMo0z8JXZROC2AFsoo9OnmoC2oTaqXGSX+0S7cRmPRj3Hi1Q9R50YA8QcAmJIHDx5kFy5cKFwwjvQSdjy7Tf2iPZIKbVuwSEeTir/wJX2buLlxXPVHJPaPrxLUAeIPADAl79+/zw4cOJB/9hegSyD+AAD7QH/0w4N/0DUQfwCAfbCxscGDf9A5EH8AgH1y/PhxHvyDToH4AwDsk/v37/PgH3QKxB8AYJ/w4B90DcQfAKAG9ODfzZs3CxdAu0H8AQBqYGtrK//ev777D8NG//h47969wtVOEH8AgJo4c+ZM/uEfGCYvX77M/+1RRvY2g/gDANTE06dPs2PHjhUuGAq62nP9+vXs8OHD2aNHjwrfdoP4AwDUiMRfmwAYBs+fP8+OHj2aP/OhBz+7AuIPAFAjuuyvy//QbyT0ly5dys/2u7jZQ/wBAGpEl4D14J8eAIR+IrGX6HftbD+C+AMA1Ixe+ZMwQL/Y3d3Nj2tXz/YjiD8AQM3oYz8LCwt89KdH6N6+/sOhy2f7EcQfAGAGXLt2LTfQbXS2f/Xq1V6c7UcQfwCAGcDZf/fp29l+BPEHAJgROvPXE+HQLfp6th9B/AEAZoTO+vWHP69fvy58oO30+Ww/gvgDAMyQlZUVnvzvAEM4248g/gAAM0Rnj3rvn7P/9iKx19m+xL/PZ/sRxB8AYMZw9t9O3r17lx8XCb8u9w8JxB8AYMb47P/Vq1eFD8ybx48fZ4cOHcr/kGeIf8OM+AMANID+351v/s+f7e3tbGlpKTt+/Hi2sbFR+A4PxB8AoAE+fPiQC87a2lrhA02i/tcGTFdgdBtG7iGD+AMANITuK+tpcj1ZDs2xubmZnTx5Mjt9+jS3XgoQfwCABlleXs5u3LhRuGCWaJOlDy3p3v7q6mrhCwLxBwBoEN1z5sM/s+fJkyf5VRY9za+n+uFTEH8AgIa5detWdu7cucIFdaJNlfr22LFjg3t9bxIQfwCAhtGrZUePHs3PTqEe1Kc3b97MH+i7ffv24B/o2wvEHwBgDjx79iy/F80l6f2jNyh0iV/PU+i2CuwN4g8AMCf0MBqX/6fn5cuX+bcT9ArlixcvCl+oAuIPADAndKn6xIkT+fvnUB19MVEbJ13iv3//Ppf4pwDxBwCYI3rvXCK2tbVV+MAotFm6e/du3l+XLl3ilsk+QPwBAObMgwcP8kvXfPxnNI8ePcofkjx//jwf6qkBxB8AoAVcuHAhu3z5cuECo9f1dGvkiy++4NW9GkH8AQBagO5j64n1hw8fFj7DRrdB9Ac8vBI5GxB/AICWoMvZev1vyGIn0delffWDbofwMN9sQPwBAFqEXlmT8A3t1bUo+nr7YYj/sd8kiD8AQMvwd+mH8GAboj8fEH8AgBaiS96Li4vZzs5O4dMvEP35gvgDALSUlZWV/A9q+rQBePr0af5VQz3Ih+jPD8QfAKDF6B8AdQtAZ8pdRd8vkNBL8PU5Xt3W4EG++YL4AwC0nMePH+eXx3XW3CX097r6DK/qri/y6Vv80A4QfwCADrC5uZlfAdDnbduMzvL1NT69o6/66u91+Qxv+0D8AQA6gu7962t3+hKgPgrUFnQJX5fyv/zyy/y7+/prXS7ttxvEHwCgQ+jMWpfQdSldZ9jzRN8icF10L391dZX/J+gIiD8AQAfZ2NjI/wxIVwLW1tYaOcvWdwf0CqLO7CX4/jvi7e3tIgZ0BcQfAKCjSPD1MKD+9Eb312/cuJFfbq/rlsDbt2/zs/mLFy/mYq/vDsiuKw59/f7AUED8AQB6gF4F1MN1eod+YWEhvyqgZwMk1Dpjl5CXGT2Rv76+np/RX79+Pf/wjtIeOHAgF3yd5StM8aA/IP4AAD1EmwFdkpd46/16nbWPMrpfr3v32jzoSoLeLGjTA4VQP4g/AADAwED8AQAABkWW/X9eQAMMKJ0j5AAAAABJRU5ErkJggg==)\n",
        "\n"
      ],
      "metadata": {
        "id": "bj0GJa32D04B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* BoW(Bag of Words)\n",
        "  - 단어들의 순서는 고려하지 않고, 출현 빈도에만 집중하는 텍스트 데이터의 수치화 표현 방법\n",
        "  -\n",
        "  (1) 각 단어에 고유한 정수 인덱스 부여\n",
        "  (2) 각 인덱스의 위치에 단어 토큰의 등장 횟수를 기록한 벡터 생성\n",
        "\n",
        "* DTM(Document-Term Matrix) : 문서 단어 행렬\n",
        "  - 각 문서에 대한 BoW를 하나의 행렬로 만드는 것\n",
        "\n",
        "* TF-IDF(Term Frequency-Inverse Document Frequency)\n",
        "  - 단어의 빈도와 역 문서 빈도(문서의 빈도에 특정 식을 취함)를 사용하여 DTM 내의 각 단어들마다 중요한 정도를 가중치로 주는 방법\n",
        "  - (1) tf(d,t) : 특정 문서 d에서의 특정 단어 t의 등장 횟수.\n",
        "  - (2) df(t) : 특정 단어 t가 등장한 문서의 수.\n",
        "  - (3) idf(d, t) : df(t)에 반비례하는 수."
      ],
      "metadata": {
        "id": "G0EUr_LvEQoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Okt\n",
        "\n",
        "okt = Okt()\n",
        "\n",
        "def build_bag_of_words(document):\n",
        "  # 온점 제거 및 형태소 분석\n",
        "  document = document.replace('.', '')\n",
        "  tokenized_document = okt.morphs(document)\n",
        "\n",
        "  word_to_index = {}\n",
        "  bow = []\n",
        "\n",
        "  for word in tokenized_document:  \n",
        "    if word not in word_to_index.keys():\n",
        "      word_to_index[word] = len(word_to_index)  \n",
        "      # BoW에 전부 기본값 1을 넣는다.\n",
        "      bow.insert(len(word_to_index) - 1, 1)\n",
        "    else:\n",
        "      # 재등장하는 단어의 인덱스\n",
        "      index = word_to_index.get(word)\n",
        "      # 재등장한 단어는 해당하는 인덱스의 위치에 1을 더한다.\n",
        "      bow[index] = bow[index] + 1\n",
        "\n",
        "  return word_to_index, bow\n",
        "\n",
        "doc1 = \"정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다.\"\n",
        "vocab, bow = build_bag_of_words(doc1)\n",
        "print('vocabulary :', vocab)\n",
        "print('bag of words vector :', bow)\n",
        "\n",
        "doc2 = '소비자는 주로 소비하는 상품을 기준으로 물가상승률을 느낀다.'\n",
        "\n",
        "vocab, bow = build_bag_of_words(doc2)\n",
        "print('vocabulary :', vocab)\n",
        "print('bag of words vector :', bow)\n",
        "\n",
        "doc3 = doc1 + ' ' + doc2\n",
        "vocab, bow = build_bag_of_words(doc3)\n",
        "print('vocabulary :', vocab)\n",
        "print('bag of words vector :', bow)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyO3QmYKFbB7",
        "outputId": "8a023cff-806a-4454-c689-db645973856c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocabulary : {'정부': 0, '가': 1, '발표': 2, '하는': 3, '물가상승률': 4, '과': 5, '소비자': 6, '느끼는': 7, '은': 8, '다르다': 9}\n",
            "bag of words vector : [1, 2, 1, 1, 2, 1, 1, 1, 1, 1]\n",
            "vocabulary : {'소비자': 0, '는': 1, '주로': 2, '소비': 3, '하는': 4, '상품': 5, '을': 6, '기준': 7, '으로': 8, '물가상승률': 9, '느낀다': 10}\n",
            "bag of words vector : [1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1]\n",
            "vocabulary : {'정부': 0, '가': 1, '발표': 2, '하는': 3, '물가상승률': 4, '과': 5, '소비자': 6, '느끼는': 7, '은': 8, '다르다': 9, '는': 10, '주로': 11, '소비': 12, '상품': 13, '을': 14, '기준': 15, '으로': 16, '느낀다': 17}\n",
            "bag of words vector : [1, 2, 1, 2, 3, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 06. 머신 러닝"
      ],
      "metadata": {
        "id": "IrN_6hrFG3mT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 하이퍼 파라미터\n",
        "  - 모델의 성능에 영향을 주는 사람이 값을 지정하는 변수\n",
        "* 매개변수\n",
        "  - 가중치와 편향\n",
        "  - 학습을 하는 동안 값이 계속해서 변하는 수\n",
        "\n",
        "* 회귀\n",
        "  - 선형 회귀(Linear Regression)\n",
        "  - 어떠한 연속적인 값의 범위 내에서 예측값이 나오는 경우\n",
        "  - 기존의 분류 문제와 같이 분리된(비연속적인) 답이 결과가 아니라 연속된 값을 결과로 가지는 문제\n",
        "\n",
        "* 분류\n",
        "  - 로지스틱 회귀(Logistic Regression)\n",
        "  - 주어진 입력에 대해서 두 개의 선택지 중 하나의 답을 선택해야 하는 경우\n",
        "\n",
        "* 혼동 행렬\n",
        "  - 맞춘 결과와 틀린 결과에 대한 세부적인 내용을 위해서 사용\n",
        "  - True Positive(TP) : 실제 True인 정답을 True라고 예측 (정답)\n",
        "  - False Positive(FP) : 실제 False인 정답을 True라고 예측 (오답)\n",
        "  - False Negative(FN) : 실제 True인 정답을 False라고 예측 (오답)\n",
        "  - True Negative(TN) : 실제 False인 정답을 False라고 예측 (정답)\n",
        "---\n",
        "* 과적합\n",
        "  - 훈련 데이터를 과하게 학습한 경우\n",
        "\n",
        "* 과소 적합\n",
        "  - 테스트 데이터의 성능이 올라갈 여지가 있음에도 훈련을 덜 한 상태\n",
        "---\n",
        "* 선형 회귀(Linear Regression)\n",
        "  - 한 개 이상의 독립 변수 x와 y의 선형 관계를 모델링\n",
        "  - 독립 변수가 1개라면 단순 선형 회귀\n",
        "  - 독립 변수가 여러 개라면 다중 선형 회귀\n",
        "* 로지스틱 회귀\n",
        "  - 2개 중 하나를 결정하는 문제를 풀기 위한 대표적인 알고리즘\n",
        "* 소프트맥스 회귀\n",
        "  - 3개 이상의 선택지 중에서 1개를 고르는 다중 클래스 분류 문제를 위한 회귀\n",
        "---\n",
        "* 목적함수/비용함수/손실함수\n",
        "  - 실제값과 예측값에 대한 오차에 대한 식\n",
        "  - 선형 회귀(회귀) : 평균 제곱 오차(Mean Squared Error, MSE) 사용\n",
        "  - 로지스틱 회귀(분류) : 크로스 엔트로피 함수\n",
        "  - 소프트맥스 회귀(분류) : 크로스 엔트로피 함수\n",
        "* 옵티마이저\n",
        "  - 비용 함수를 최소화 하는 매개변수인 w와 b를 찾기 위한 알고리즘\n",
        "  - 훈련/학습 : 옵티마이저를 통해 적절한 w와 b를 찾아내는 과정\n",
        "  - 경사하강법 : 대표적인 옵티마이저 알고리즘\n",
        "---\n",
        "* 시그모이드 함수\n",
        "  - 입력된 데이터에 대해서 0과 1사이의 값을 출력하여 해당 값이 둘 중 하나에 속할 확률로 해석할 수 있도록 만들어준다\n",
        "\n",
        "* 소프트맥스 함수\n",
        "  - 선택해야 하는 선택지의 총 개수를 k라고 할 때, k차원의 벡터를 입력받아 각 클래스에 대한 확률을 추정\n"
      ],
      "metadata": {
        "id": "vrJNYwRRG55z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 07. 딥 러닝"
      ],
      "metadata": {
        "id": "yKwZ15mfQUut"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 딥 러닝\n",
        "  - 머신 러닝의 특정한 한 분야로, 인공 신경망의 층을 연속적으로 깊게 쌓아올려 데이터를 학습하는 방식\n",
        "* 퍼셉트론\n",
        "  - 인공 신경망으로 다수의 입력으로부터 하나의 결과를 내보내는 알고리즘\n",
        "* 활성화 함수\n",
        "  - 뉴런에서 출력값을 변경시키는 함수\n",
        "    - 1) 계단 함수\n",
        "    - 2) 시그모이드 함수\n",
        "      - 이진 분류 문제에 사용\n",
        "      - 은닉층에서 사용하면 매개변수 w가 업데이트 되지 않아 학습이 안되기 때문에 사용을 지양\n",
        "    - 3) 하이퍼볼릭탄젠트 함수\n",
        "    - 4) 렐루 함수\n",
        "    - 5) 리키 렐루 함수\n",
        "    - 6) 소프트맥스 함수\n",
        "      - 시그모이드 함수처럼 출력층에서 주로 사용\n",
        "      - 다중 클래스 분류 문제에 사용\n",
        "* 심층 신경망\n",
        "  - 은닉층이 2개 이상인 신경망\n",
        "* 에포크\n",
        "  - 인공 신경망에서 전체 데이터에 대해서 순전파와 역전파가 끝난 상태\n",
        "  - 에포크 횟수가 지나치거나 너무 적으면 앞서 배운 과적합과 과소적합이 발생할 수 있다.\n",
        "* 배치 크기\n",
        "  - 몇 개의 데이터 단위로 매개변수를 업데이트 하는지\n",
        "* 이터레이션\n",
        "  - 한 번의 에포크를 끝내기 위해서 필요한 배치의 수\n",
        "  - 전체 데이터가 2,000일 때 배치 크기를 200으로 한다면 이터레이션의 수는 총 10\n",
        "---\n",
        "* 기울기 소실\n",
        "  - 입력층에 가까운 층들에서 가중치들이 업데이트가 제대로 되지 않으면 결국 최적의 모델을 찾을 수 없게 되는 현상\n",
        "* 기울기 폭주\n",
        "  - 기울기가 점차 커지더니 가중치들이 비정상적으로 큰 값이 되면서 결국 발산되는 현상\n",
        "---\n",
        "* 다층 퍼셉트론(MLP)\n",
        "  - 단층 퍼셉트론의 형태에서 은닉층이 1개 이상 추가된 신경망\n",
        "* 피드 포워드 신경망\n",
        "  - 입력층에서 출력층으로 오직 한 방향으로만 연산 방향이 정해져 있는 신경망\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "En61fBI4QZgS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 08. 순환 신경망"
      ],
      "metadata": {
        "id": "WmwIX16A0EmV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* FFNN(피드 포워드 신경망)\n",
        "  - 은닉층에서 활성화 함수를 지난 값이 오직 출력층 방향으로만 향하는 신경망\n",
        "\n",
        "* RNN(순환 신경망)\n",
        "  - 은닉층의 노드에서 활성화 함수를 통해 나온 결과값을 출력층 방향으로도 보내고, 다시 은닉층 노드의 다음 계산의 입력으로 보내는 신경망"
      ],
      "metadata": {
        "id": "RH0Vqyb80ITq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 09. 워드 임배딩"
      ],
      "metadata": {
        "id": "vsFzf9y-zq4o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 희소 표현\n",
        "  - 벡터 또는 행렬의 값이 대부분이 0으로 표현되는 방법\n",
        "  - 단어의 개수가 늘어나면 벡터의 차원이 한없이 커짐\n",
        "  - 단어의 의미를 표현하지 못함\n",
        "  - 원핫벡터 : 단어 벡터간 유의미한 유사도를 계산할 수 없다\n",
        "  - DTM도 희소 벡터의 일종\n",
        "\n",
        "* 밀집 표현\n",
        "  - 워드 임베딩(word embedding) : 밀집 벡터의 형태로 표현하는 방법;분산 표현을 이용하여 단어 간 의미적 유사성을 벡터화하는 작업 \n",
        "  \n",
        "  - 워드 임베딩 방법론으로는 LSA, Word2Vec, FastText, Glove 등이 있다.\n",
        "---\n",
        "* Word2Vec(워드투벡터)\n",
        "  - 단어 벡터 간 유의미한 유사도를 반영할 수 있도록 단어의 의미를 수치화 할 수 있는 방법\n",
        "  - Word2Vec의 학습 방식에는 CBOW(Continuous Bag of Words)와 Skip-Gram 두 가지 방식이 있다.\n",
        "    - CBOW : 주변 단어를 통해 중심 단어를 예측\n",
        "    - Skip-gram : 중심 단어에서 주변 단어를 예측\n",
        "    - 전반적으로 Skip-gram이 CBOW보다 성능이 좋다고 알려져 있다.\n",
        "  - Word2Vec에서 입력은 모두 원-핫 벡터가 되어야 한다.\n",
        "  - Word2Vec은 은닉층이 다수인 딥 러닝(deep learning) 모델이 아니라 은닉층이 1개인 얕은 신경망이다.\n",
        "  - Word2Vec의 은닉층은 일반적인 은닉층과는 달리 활성화 함수가 존재하지 않으며 룩업 테이블이라는 연산을 담당하는 층으로 투사층이라고 부르기도 한다.\n",
        "\n",
        "* GloVe(글로브)\n",
        "  - 미국 스탠포드대학에서 개발한 단어 임베딩 방법\n",
        "  - 카운트 기반과 예측 기반을 모두 사용\n",
        "  - 카운트 기반의 LSA(Latent Semantic Analysis)와 예측 기반의 Word2Vec의 단점을 지적하며 이를 보완한다는 목적\n",
        "  - \n",
        "\n",
        "* FastText(패스트텍스트)\n",
        "  - 페이스북에서 개발한 단어를 벡터로 만드는 또 다른 방법\n",
        "  - Word2Vec 이후에 나온, 메커니즘 자체는 Word2Vec의 확장판\n",
        "  - Word2Vec는 단어를 쪼개질 수 없는 단위로 생각한다면, FastText는 하나의 단어 안에도 여러 단어들이 존재하는 것으로 간주;내부 단어. 즉, 서브워드(subword)를 고려하여 학습\n",
        "    - FastText에서는 각 단어는 글자 단위 n-gram의 구성으로 취급\n",
        "    - 시작과 끝을 의미하는 <, >를 도입하여 내부 단어(subword)와 기존 단어 토큰 벡터로 만듬 \n",
        "    - ex) 트라이그램(tri-gram)의 경우, apple은 app, ppl, ple로 분리하고 이들을 벡터로 만든다 : <ap, app, ppl, ple, le>, <apple>\n",
        "\n",
        "* ELMo(엘모, Embeddings from Language Model)\n",
        "  - 새로운 워드 임베딩 방법\n",
        "  - 사전 훈련된 언어 모델을 사용\n",
        "  - 워드 임베딩 시 문맥을 고려해서 임베딩\n"
      ],
      "metadata": {
        "id": "YKObjATczu2q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 14. RNN을 이용한 인코더-디코더\n"
      ],
      "metadata": {
        "id": "jEueNKj6I9q2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 시퀀스-투-시퀀스(Sequence-to-Sequence, seq2seq)\n",
        "  - 입력된 시퀀스로부터 다른 도메인의 시퀀스를 출력하는 다양한 분야에서 사용되는 모델\n",
        "  - 번역기에서 대표적으로 사용되는 모델\n",
        "  - 크게 인코더와 디코더라는 두 개의 모듈로 구성\n",
        "    - 인코더는 입력 문장의 모든 단어들을 순차적으로 입력받은 뒤에 마지막에 이 모든 단어 정보들을 압축해서 하나의 벡터(컨텍스트 벡터)로 만듬\n",
        "    - 디코더는 컨텍스트 벡터를 받아서 번역된 단어를 한 개씩 순차적으로 출력\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ATRstMjeJAmW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 15. 어텐션 메커니즘"
      ],
      "metadata": {
        "id": "8gSPLXYIJUL5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* RNN에 기반한 seq2seq 모델의 보완책\n",
        "  - seq2seq의 문제점\n",
        "    - 하나의 고정된 크기의 벡터에 모든 정보를 압축하려고 하니까 정보 손실이 발생\n",
        "    - RNN의 고질적인 문제인 기울기 소실 문제가 존재\n",
        "  - 문제점들로 인해 번역 분야에서 입력 문장이 길면 번역 품질이 떨어지는 현상 발생\n",
        "  - 입력 시퀀스가 길어지면 출력 시퀀스의 정확도가 떨어지는 것을 보정해주기 위해 등장한 기법\n",
        "\n",
        "* 어텐션의 아이디어\n",
        "  - 디코더에서 출력 단어를 예측하는 매 시점마다, 인코더에서의 전체 입력 문장을 다시 한 번 참고\n",
        "  - 해당 시점에서 예측해야할 단어와 연관이 있는 입력 단어 부분을 좀 더 집중\n",
        "\n",
        "* 어텐션 함수\n",
        "  - Attention Value = Attention(Q, K, V)\n",
        "    - Q = Query : t 시점의 디코더 셀에서의 은닉 상태\n",
        "    - K = Keys : 모든 시점의 인코더 셀의 은닉 상태들\n",
        "    - V = Values : 모든 시점의 인코더 셀의 은닉 상태들\n",
        "    - t = 어텐션 메커니즘이 수행되는 디코더 셀의 현재 시점을 의미.\n",
        "\n",
        "* 어텐션의 종류\n",
        "  - 닷-프로덕트 어텐션(Dot-Product Attention)\n",
        "  - 바다나우 어텐션(Bahdanau Attention)\n",
        "  \n",
        "* 어텐션의 연산 순서\n",
        "  - 어텐션 스코어를 구한다\n",
        "  - 소프트맥스 함수를 통해 어텐션 분포를 구한다\n",
        "  - 각 인코더의 어텐션 가중치와 은닉 상태를 가중합하여 어텐션 값을 구한다\n",
        "  - 컨텍스트 벡터로부터 st를 구한다\n",
        "\n",
        "\n",
        "* 바다나우 어텐션\n",
        "  - Attention Value = Attention(Q, K, V)\n",
        "  - Q = Query : t-1 시점의 디코더 셀에서의 은닉 상태\n",
        "  - K = Keys : 모든 시점의 인코더 셀의 은닉 상태들\n",
        "  - V = Values : 모든 시점의 인코더 셀의 은닉 상태들\n",
        "    - t = 어텐션 메커니즘이 수행되는 디코더 셀의 현재 시점을 의미."
      ],
      "metadata": {
        "id": "huM1UUz4JWLZ"
      }
    }
  ]
}